<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Retrieve Large Dataset in Elasticsearch - KK's Blog (fromkk)</title><meta name=Description content="fromkk.com is my personal blog, Explore insightful posts on Python, machine learning, and other stuff. keyword: python, machine learning, programming"><meta property="og:url" content="https://fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/"><meta property="og:site_name" content="KK's Blog (fromkk)"><meta property="og:title" content="Retrieve Large Dataset in Elasticsearch"><meta property="og:description" content="It’s easy to get small dataset from Elasticsearch by using size and from. However, it’s impossible to retrieve large dataset in the same way.
Deep Paging Problem As we know it, Elasticsearch data is organised into indexes, which is a logical namespace, and the real data is stored into physical shards. Each shard is an instance of Lucene. There are two kind of shards, primary shards and replica shards. Replica shards is the copy of primary shards in case nodes or shards fail. By distributing documents in an index across multiple shards, and distributing those shards across multiple nodes, Elasticsearch can ensure redundancy and scalability. By default, Elasticsearch create 5 primary shards and one replica shard for each primary shards."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-21T20:33:00+08:00"><meta property="article:modified_time" content="2025-08-10T18:44:06+08:00"><meta property="article:tag" content="Elasticsearch"><meta property="og:image" content="https://fromkk.com/images/avatar.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://fromkk.com/images/avatar.png"><meta name=twitter:title content="Retrieve Large Dataset in Elasticsearch"><meta name=twitter:description content="It’s easy to get small dataset from Elasticsearch by using size and from. However, it’s impossible to retrieve large dataset in the same way.
Deep Paging Problem As we know it, Elasticsearch data is organised into indexes, which is a logical namespace, and the real data is stored into physical shards. Each shard is an instance of Lucene. There are two kind of shards, primary shards and replica shards. Replica shards is the copy of primary shards in case nodes or shards fail. By distributing documents in an index across multiple shards, and distributing those shards across multiple nodes, Elasticsearch can ensure redundancy and scalability. By default, Elasticsearch create 5 primary shards and one replica shard for each primary shards."><meta name=application-name content="My cool site"><meta name=apple-mobile-web-app-title content="My cool site"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/><link rel=prev href=https://fromkk.com/posts/program-crash-caused-by-cpu-instruction/><link rel=next href=https://fromkk.com/posts/using-cibuildwheel-to-create-python-wheels/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Retrieve Large Dataset in Elasticsearch","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/fromkk.com\/posts\/retrieve-large-dataset-in-elasticsearch\/"},"genre":"posts","keywords":"Elasticsearch","wordcount":934,"url":"https:\/\/fromkk.com\/posts\/retrieve-large-dataset-in-elasticsearch\/","datePublished":"2020-06-21T20:33:00+08:00","dateModified":"2025-08-10T18:44:06+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"KK"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="KK's Blog (fromkk)"><span class=header-title-pre><img class='logo lazyautosizes ls-is-cached lazyloaded' src=/images/avatar.png></span>KK's Blog (fromkk)</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>Posts </a><a class=menu-item href=/categories/>Categories </a><a class=menu-item href=/tags/>Tags </a><a class=menu-item href=/about/>About </a><a class=menu-item href=https://github.com/bebound/bebound.github.io title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw' aria-hidden=true></i> </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="KK's Blog (fromkk)"><span class=header-title-pre><img class='logo lazyautosizes ls-is-cached lazyloaded' src=/images/avatar.png></span>KK's Blog (fromkk)</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/categories/ title>Categories</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/about/ title>About</a><a class=menu-item href=https://github.com/bebound/bebound.github.io title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw' aria-hidden=true></i></a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Retrieve Large Dataset in Elasticsearch</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>KK</a></span>&nbsp;<span class=post-category>included in <a href=/categories/misc/><i class="far fa-folder fa-fw" aria-hidden=true></i>Misc</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2020-06-21>2020-06-21</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;934 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;2 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#deep-paging-problem>Deep Paging Problem</a></li><li><a href=#scroll>Scroll</a><ul><li><a href=#slice>Slice</a></li></ul></li><li><a href=#search-after>Search After</a></li><li><a href=#ref>Ref</a></li></ul></nav></div></div><div class=content id=content><p>It&rsquo;s easy to get small dataset from Elasticsearch by using <code>size</code> and <code>from</code>. However, it&rsquo;s impossible to retrieve large dataset in the same way.</p><h2 id=deep-paging-problem>Deep Paging Problem</h2><p>As we know it, Elasticsearch data is organised into indexes, which is a logical namespace, and the real data is stored into physical shards. Each shard is an instance of Lucene. There are two kind of shards, primary shards and replica shards. Replica shards is the copy of primary shards in case nodes or shards fail. By distributing documents in an index across multiple shards, and distributing those shards across multiple nodes, Elasticsearch can ensure redundancy and scalability. By default, Elasticsearch create <strong>5</strong> primary shards and one replica shard for each primary shards.</p><figure><img src=/images/elasticsearch_cluster.png width=600></figure><p>How to decide which shard should the document be distributed? By default, <code>shard = hashCode(doc._id) % primary_shards_number</code>. To make this stable, the number of primary shards cannot be change the index has been created.</p><p>Usually, the shards size should be 20GB to 40GB. The number of shards a node can hold is depending on the heap space. In general, 1GB heap space can hold 20 shards.</p><p>As data is store in different shards. If there are 5 shards, when doing this query:</p><pre tabindex=0><code class=language-nil data-lang=nil>GET /_search?size=10
</code></pre><p>Each shards will generate 10 search result, and send results to coordinate node. The coordinate node will sort 50 items, and result the first 10 result to user. However when query become this:</p><pre tabindex=0><code class=language-nil data-lang=nil>GET /_search?size=10&amp;from=10000
</code></pre><p>Although we only need 10 items, each shards has to return the first 10010 result to coordinate node, and coordinate node has to sort 50050 items, this search cost lots of resource.</p><p>As deep paging is costly, Elasticsearch has restrict <code>from+size</code> less than <code>index.max-result-window</code>, the default value is <code>10000</code>.</p><h2 id=scroll>Scroll</h2><p>The <code>search</code> method has to retrieve and sort the result over and over again, because it does not know how to continue the search from previous position.</p><p><code>scroll</code> is more efficient when retrieve large set of data.</p><p>For example:</p><pre tabindex=0><code class=language-nil data-lang=nil>POST /twitter/_search?scroll=1m
{
    &#34;size&#34;: 100,
    &#34;query&#34;: {
        &#34;match&#34; : {
            &#34;title&#34; : &#34;elasticsearch&#34;
        }
    }
}
</code></pre><p>and the returned result will contains a <code>_scroll_id</code>, which should be passed to the <code>scroll</code> API in order to retrieve the rest of data.</p><pre tabindex=0><code class=language-nil data-lang=nil>POST /_search/scroll
{
    &#34;scroll&#34; : &#34;1m&#34;,
    &#34;scroll_id&#34; : &#34;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==&#34;
}
</code></pre><p><code>Scroll</code> return the matched result at the time of the initial search request, like a snapshot, and ignore the subsequent changes to the documents(index, update or delete). The <code>scroll=1m</code> is used to tell how long should Elasticsearch keep the context. If there no following requests using the returned <code>scroll_id</code>, the scroll context will expire.</p><p>PS: In fact, when dealing the initial search request, <code>scoll</code> will cache all the matched documents&rsquo; id, then get the <code>size</code> document content in batches for each following requests.</p><h3 id=slice>Slice</h3><p>It&rsquo;s also possible to split the scroll in multiple slices and consume them independently.</p><pre tabindex=0><code class=language-nil data-lang=nil>GET /twitter/_search?scroll=1m
{
    &#34;slice&#34;: {
        &#34;id&#34;: 0,
        &#34;max&#34;: 2
    },
    &#34;query&#34;: {
        &#34;match&#34; : {
            &#34;title&#34; : &#34;elasticsearch&#34;
        }
    }
}
GET /twitter/_search?scroll=1m
{
    &#34;slice&#34;: {
        &#34;id&#34;: 1,
        &#34;max&#34;: 2
    },
    &#34;query&#34;: {
        &#34;match&#34; : {
            &#34;title&#34; : &#34;elasticsearch&#34;
        }
    }
}
</code></pre><p>The above request contains split the slice into <code>2</code> parts by using <code>max:2</code> parameter. These union of two requests&rsquo; data is equivalent to the result of a scroll query without slicing.</p><p>The slice of the document can be calculated by this formula: <code>slice(doc) = hash(doc._id) % max_slice</code>. This is quiet similar to the calculation of shards mentioned before. For example if slice is 4, and shards is 2. Then slices <code>0,2</code> are assigned to first shard and slices <code>1,3</code> are assigned to second shard.</p><p>When slices number is <code>n</code>, each matched documents use a <code>n</code> bitset to remember which slice it belongs to. So you should limit the number of sliced query you perform in parallel to avoid the memory explosion.</p><p>Getting <code>hash(doc._id)</code> is expensive. You can also use another numeric <code>doc_value</code> field to do the slicing without hash function. For instance:</p><pre tabindex=0><code class=language-nil data-lang=nil>GET /twitter/_search?scroll=1m
{
    &#34;slice&#34;: {
        &#34;field&#34;: &#34;date&#34;,
        &#34;id&#34;: 0,
        &#34;max&#34;: 10
    },
    &#34;query&#34;: {
        &#34;match&#34; : {
            &#34;title&#34; : &#34;elasticsearch&#34;
        }
    }
}
</code></pre><blockquote><p>Query performance is most efficient when the number of slices is equal to the number of shards in the index. If that number is large (e.g. 500), choose a lower number as too many slices will hurt performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.</p><p>from <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html#docs-reindex-automatic-slice target=_blank rel="noopener noreffer">Picking the number of slices</a></p></blockquote><h2 id=search-after>Search After</h2><p>Scroll is not suitable for real-time user requests. After Elasticsearch 5, <code>Search After</code> API is added. It&rsquo;s similar to scroll but provides a live cursor. It uses the results from the previous page to retrieve the next page.</p><p>To use search after, the query must be sorted, and the following query also contains <code>search_after=previous sort value</code>.</p><p>For example, if the initial query is this:</p><pre tabindex=0><code class=language-nil data-lang=nil>GET twitter/_search
{
    &#34;size&#34;: 10,
    &#34;query&#34;: {
        &#34;match&#34; : {
            &#34;title&#34; : &#34;elasticsearch&#34;
        }
    },
    &#34;sort&#34;: [
        {&#34;date&#34;: &#34;asc&#34;},
        {&#34;tie_breaker_id&#34;: &#34;asc&#34;}
    ]
}
</code></pre><p>Then you have to extract the sort value of the last document, and pass it to <code>search_after</code> to get the next page result.</p><pre tabindex=0><code class=language-nil data-lang=nil>GET twitter/_search
{
    &#34;size&#34;: 10,
    &#34;query&#34;: {
        &#34;match&#34; : {
            &#34;title&#34; : &#34;elasticsearch&#34;
        }
    },
    &#34;search_after&#34;: [1463538857, &#34;654323&#34;],
    &#34;sort&#34;: [
        {&#34;date&#34;: &#34;asc&#34;},
        {&#34;tie_breaker_id&#34;: &#34;asc&#34;}
    ]
}
</code></pre><h2 id=ref>Ref</h2><ol><li><a href=https://www.elastic.co/guide/en/elasticsearch/guide/current/pagination.html target=_blank rel="noopener noreffer">Elasticsearch: The Definitive Guide: Pagination</a></li><li><a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html target=_blank rel="noopener noreffer">Scalability and resilience: clusters, nodes, and shards</a></li><li><a href=http://arganzheng.life/deep-pagination-in-elasticsearch.html target=_blank rel="noopener noreffer">ElasticSearch如何支持深度分页</a></li><li><a href=https://discuss.elastic.co/t/documentation-for-scroll-api-is-a-bit-confusing/185954 target=_blank rel="noopener noreffer">Documentation for scroll API is a bit confusing!</a></li><li><a href=https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-request-scroll.html target=_blank rel="noopener noreffer">Request Body Search: Scroll</a></li><li><a href=https://qbox.io/blog/optimizing-elasticsearch-how-many-shards-per-index target=_blank rel="noopener noreffer">Optimizing Elasticsearch: How Many Shards per Index?</a></li></ol></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2025-08-10</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/ data-title="Retrieve Large Dataset in Elasticsearch" data-hashtags=Elasticsearch><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/ data-hashtag=Elasticsearch><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/ data-title="Retrieve Large Dataset in Elasticsearch"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/ data-title="Retrieve Large Dataset in Elasticsearch"><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/ data-title="Retrieve Large Dataset in Elasticsearch"><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/elasticsearch/>Elasticsearch</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/program-crash-caused-by-cpu-instruction/ class=prev rel=prev title="Program Crash Caused by CPU Instruction"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Program Crash Caused by CPU Instruction</a>
<a href=/posts/using-cibuildwheel-to-create-python-wheels/ class=next rel=next title="Using cibuildwheel to Create Python Wheels">Using cibuildwheel to Create Python Wheels<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div id=comments><div id=utterances class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://utteranc.es/>utterances</a>.</noscript></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.148.2">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.3.0"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2017 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>KK</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{utterances:{darkTheme:"github-dark",issueTerm:"pathname",label:"utterances",lightTheme:"github-light",repo:"bebound/bebound.github.io"}},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>