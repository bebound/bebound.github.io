<!doctype html><html lang=en><head><title>Retrieve Large Dataset in Elasticsearch Â· KK's Blog (fromkk)
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="KK"><meta name=description content="It&rsquo;s easy to get small dataset from Elasticsearch by using size and from. However, it&rsquo;s impossible to retrieve large dataset in the same way.
Deep Paging Problem Link to heading As we know it, Elasticsearch data is organised into indexes, which is a logical namespace, and the real data is stored into physical shards. Each shard is an instance of Lucene. There are two kind of shards, primary shards and replica shards."><meta name=keywords content="fromkk,blog,kk blog,developer,personal,python,golang,go,linux,machine learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="Retrieve Large Dataset in Elasticsearch"><meta name=twitter:description content="It&rsquo;s easy to get small dataset from Elasticsearch by using size and from. However, it&rsquo;s impossible to retrieve large dataset in the same way.
Deep Paging Problem Link to heading As we know it, Elasticsearch data is organised into indexes, which is a logical namespace, and the real data is stored into physical shards. Each shard is an instance of Lucene. There are two kind of shards, primary shards and replica shards."><meta property="og:title" content="Retrieve Large Dataset in Elasticsearch"><meta property="og:description" content="It&rsquo;s easy to get small dataset from Elasticsearch by using size and from. However, it&rsquo;s impossible to retrieve large dataset in the same way.
Deep Paging Problem Link to heading As we know it, Elasticsearch data is organised into indexes, which is a logical namespace, and the real data is stored into physical shards. Each shard is an instance of Lucene. There are two kind of shards, primary shards and replica shards."><meta property="og:type" content="article"><meta property="og:url" content="https://www.fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-21T20:33:00+08:00"><meta property="article:modified_time" content="2020-06-21T20:33:15+08:00"><link rel=canonical href=https://www.fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/><link rel=preload href="https://www.fromkk.com/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=https://www.fromkk.com/css/coder.min.ea4c355c5f9913809f506132a80bf3fab84f2679dee370f334f7385a36d24c38.css integrity="sha256-6kw1XF+ZE4CfUGEyqAvz+rhPJnne43DzNPc4WjbSTDg=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://www.fromkk.com/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=https://www.fromkk.com/images/favicon.svg sizes=any><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://www.fromkk.com/icons/icon-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://www.fromkk.com/icons/icon-192x192.png><link rel=manifest href=https://www.fromkk.com/site.webmanifest><link rel=mask-icon href=https://www.fromkk.com/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://www.fromkk.com/>KK's Blog (fromkk)
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/tags/>Tags</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/index.xml>RSS</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://www.fromkk.com/posts/retrieve-large-dataset-in-elasticsearch/>Retrieve Large Dataset in Elasticsearch</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2020-06-21T20:33:00+08:00>06/21/2020
</time></span><span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
5-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=https://www.fromkk.com/tags/elasticsearch/>Elasticsearch</a></span></div></div></header><div class=post-content><p>It&rsquo;s easy to get small dataset from Elasticsearch by using <code>size</code> and <code>from</code>. However, it&rsquo;s impossible to retrieve large dataset in the same way.</p><h2 id=deep-paging-problem>Deep Paging Problem
<a class=heading-link href=#deep-paging-problem><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>As we know it, Elasticsearch data is organised into indexes, which is a logical namespace, and the real data is stored into physical shards. Each shard is an instance of Lucene. There are two kind of shards, primary shards and replica shards. Replica shards is the copy of primary shards in case nodes or shards fail. By distributing documents in an index across multiple shards, and distributing those shards across multiple nodes, Elasticsearch can ensure redundancy and scalability. By default, Elasticsearch create <strong>5</strong> primary shards and one replica shard for each primary shards.</p><figure><img src=https://www.fromkk.com/images/elasticsearch_cluster.png width=600></figure><p>How to decide which shard should the document be distributed? By default, <code>shard = hashCode(doc._id) % primary_shards_number</code>. To make this stable, the number of primary shards cannot be change the index has been created.</p><p>Usually, the shards size should be 20GB to 40GB. The number of shards a node can hold is depending on the heap space. In general, 1GB heap space can hold 20 shards.</p><p>As data is store in different shards. If there are 5 shards, when doing this query:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>GET /_search?size=10
</span></span></code></pre></div><p>Each shards will generate 10 search result, and send results to coordinate node. The coordinate node will sort 50 items, and result the first 10 result to user. However when query become this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>GET /_search?size=10&amp;from=10000
</span></span></code></pre></div><p>Although we only need 10 items, each shards has to return the first 10010 result to coordinate node, and coordinate node has to sort 50050 items, this search cost lots of resource.</p><p>As deep paging is costly, Elasticsearch has restrict <code>from+size</code> less than <code>index.max-result-window</code>, the default value is <code>10000</code>.</p><h2 id=scroll>Scroll
<a class=heading-link href=#scroll><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>The <code>search</code> method has to retrieve and sort the result over and over again, because it does not know how to continue the search from previous position.</p><p><code>scroll</code> is more efficient when retrieve large set of data.</p><p>For example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>POST /twitter/_search?scroll=1m
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;size&#34;: 100,
</span></span><span style=display:flex><span>    &#34;query&#34;: {
</span></span><span style=display:flex><span>        &#34;match&#34; : {
</span></span><span style=display:flex><span>            &#34;title&#34; : &#34;elasticsearch&#34;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>and the returned result will contains a <code>_scroll_id</code>, which should be passed to the <code>scroll</code> API in order to retrieve the rest of data.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>POST /_search/scroll
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;scroll&#34; : &#34;1m&#34;,
</span></span><span style=display:flex><span>    &#34;scroll_id&#34; : &#34;DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==&#34;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><code>Scroll</code> return the matched result at the time of the initial search request, like a snapshot, and ignore the subsequent changes to the documents(index, update or delete). The <code>scroll=1m</code> is used to tell how long should Elasticsearch keep the context. If there no following requests using the returned <code>scroll_id</code>, the scroll context will expire.</p><p>PS: In fact, when dealing the initial search request, <code>scoll</code> will cache all the matched documents&rsquo; id, then get the <code>size</code> document content in batches for each following requests.</p><h3 id=slice>Slice
<a class=heading-link href=#slice><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>It&rsquo;s also possible to split the scroll in multiple slices and consume them independently.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>GET /twitter/_search?scroll=1m
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;slice&#34;: {
</span></span><span style=display:flex><span>        &#34;id&#34;: 0,
</span></span><span style=display:flex><span>        &#34;max&#34;: 2
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    &#34;query&#34;: {
</span></span><span style=display:flex><span>        &#34;match&#34; : {
</span></span><span style=display:flex><span>            &#34;title&#34; : &#34;elasticsearch&#34;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>GET /twitter/_search?scroll=1m
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;slice&#34;: {
</span></span><span style=display:flex><span>        &#34;id&#34;: 1,
</span></span><span style=display:flex><span>        &#34;max&#34;: 2
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    &#34;query&#34;: {
</span></span><span style=display:flex><span>        &#34;match&#34; : {
</span></span><span style=display:flex><span>            &#34;title&#34; : &#34;elasticsearch&#34;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The above request contains split the slice into <code>2</code> parts by using <code>max:2</code> parameter. These union of two requests&rsquo; data is equivalent to the result of a scroll query without slicing.</p><p>The slice of the document can be calculated by this formula: <code>slice(doc) = hash(doc._id) % max_slice</code>. This is quiet similar to the calculation of shards mentioned before. For example if slice is 4, and shards is 2. Then slices <code>0,2</code> are assigned to first shard and slices <code>1,3</code> are assigned to second shard.</p><p>When slices number is <code>n</code>, each matched documents use a <code>n</code> bitset to remember which slice it belongs to. So you should limit the number of sliced query you perform in parallel to avoid the memory explosion.</p><p>Getting <code>hash(doc._id)</code> is expensive. You can also use another numeric <code>doc_value</code> field to do the slicing without hash function. For instance:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>GET /twitter/_search?scroll=1m
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;slice&#34;: {
</span></span><span style=display:flex><span>        &#34;field&#34;: &#34;date&#34;,
</span></span><span style=display:flex><span>        &#34;id&#34;: 0,
</span></span><span style=display:flex><span>        &#34;max&#34;: 10
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    &#34;query&#34;: {
</span></span><span style=display:flex><span>        &#34;match&#34; : {
</span></span><span style=display:flex><span>            &#34;title&#34; : &#34;elasticsearch&#34;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><blockquote><p>Query performance is most efficient when the number of slices is equal to the number of shards in the index. If that number is large (e.g. 500), choose a lower number as too many slices will hurt performance. Setting slices higher than the number of shards generally does not improve efficiency and adds overhead.</p><p>from <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html#docs-reindex-automatic-slice class=external-link target=_blank rel=noopener>Picking the number of slices</a></p></blockquote><h2 id=search-after>Search After
<a class=heading-link href=#search-after><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Scroll is not suitable for real-time user requests. After Elasticsearch 5, <code>Search After</code> API is added. It&rsquo;s similar to scroll but provides a live cursor. It uses the results from the previous page to retrieve the next page.</p><p>To use search after, the query must be sorted, and the following query also contains <code>search_after=previous sort value</code>.</p><p>For example, if the initial query is this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>GET twitter/_search
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;size&#34;: 10,
</span></span><span style=display:flex><span>    &#34;query&#34;: {
</span></span><span style=display:flex><span>        &#34;match&#34; : {
</span></span><span style=display:flex><span>            &#34;title&#34; : &#34;elasticsearch&#34;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    &#34;sort&#34;: [
</span></span><span style=display:flex><span>        {&#34;date&#34;: &#34;asc&#34;},
</span></span><span style=display:flex><span>        {&#34;tie_breaker_id&#34;: &#34;asc&#34;}
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Then you have to extract the sort value of the last document, and pass it to <code>search_after</code> to get the next page result.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>GET twitter/_search
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;size&#34;: 10,
</span></span><span style=display:flex><span>    &#34;query&#34;: {
</span></span><span style=display:flex><span>        &#34;match&#34; : {
</span></span><span style=display:flex><span>            &#34;title&#34; : &#34;elasticsearch&#34;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    &#34;search_after&#34;: [1463538857, &#34;654323&#34;],
</span></span><span style=display:flex><span>    &#34;sort&#34;: [
</span></span><span style=display:flex><span>        {&#34;date&#34;: &#34;asc&#34;},
</span></span><span style=display:flex><span>        {&#34;tie_breaker_id&#34;: &#34;asc&#34;}
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=ref>Ref
<a class=heading-link href=#ref><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li><a href=https://www.elastic.co/guide/en/elasticsearch/guide/current/pagination.html class=external-link target=_blank rel=noopener>Elasticsearch: The Definitive Guide: Pagination</a></li><li><a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html class=external-link target=_blank rel=noopener>Scalability and resilience: clusters, nodes, and shards</a></li><li><a href=http://arganzheng.life/deep-pagination-in-elasticsearch.html class=external-link target=_blank rel=noopener>ElasticSearchå¦ä½æ¯ææ·±åº¦åé¡µ</a></li><li><a href=https://discuss.elastic.co/t/documentation-for-scroll-api-is-a-bit-confusing/185954 class=external-link target=_blank rel=noopener>Documentation for scroll API is a bit confusing!</a></li><li><a href=https://www.elastic.co/guide/en/elasticsearch/reference/6.3/search-request-scroll.html class=external-link target=_blank rel=noopener>Request Body Search: Scroll</a></li><li><a href=https://qbox.io/blog/optimizing-elasticsearch-how-many-shards-per-index class=external-link target=_blank rel=noopener>Optimizing Elasticsearch: How Many Shards per Index?</a></li></ol></div><footer><div class=comments><script>let getTheme=window.localStorage&&window.localStorage.getItem("colorscheme"),themeInParams="preferred-color-scheme";getTheme==null&&(themeInParams!==""&&themeInParams!=="auto"?getTheme=themeInParams:getTheme=window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");let theme=getTheme==="dark"?"github-dark":"github-light",s=document.createElement("script");s.src="https://utteranc.es/client.js",s.setAttribute("repo","bebound/bebound.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("theme",theme),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s)</script></div></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>Â©
2023
KK
Â·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=https://www.fromkk.com/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-153788833-1","auto"),ga("send","pageview"))</script></body></html>