<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=content-language content="en"><meta name=author content="KK"><meta name=description content="Before talking about SimHash, let&rsquo;s review some other methods which can also identify duplication.
Longest Common Subsequence(LCS) This is the algorithm used by diff command. It is also edit distance with insertion and deletion as the only two edit operations.
This works good for short strings. However, the algorithm&rsquo;s time complexity is \(O(m*n)\), if two strings&rsquo; lengths are \(m\) and \(n\) respectively. So it&rsquo;s not suitable for large corpus. Also, if two corpus consists of same paragraph but the order is not same."><meta name=keywords content="fromkk,blog,kk blog,developer,personal,python,golang,go,linux,machine learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="Near-duplicate with SimHash"><meta name=twitter:description content="Before talking about SimHash, let&rsquo;s review some other methods which can also identify duplication.
Longest Common Subsequence(LCS) This is the algorithm used by diff command. It is also edit distance with insertion and deletion as the only two edit operations.
This works good for short strings. However, the algorithm&rsquo;s time complexity is \(O(m*n)\), if two strings&rsquo; lengths are \(m\) and \(n\) respectively. So it&rsquo;s not suitable for large corpus. Also, if two corpus consists of same paragraph but the order is not same."><meta property="og:title" content="Near-duplicate with SimHash"><meta property="og:description" content="Before talking about SimHash, let&rsquo;s review some other methods which can also identify duplication.
Longest Common Subsequence(LCS) This is the algorithm used by diff command. It is also edit distance with insertion and deletion as the only two edit operations.
This works good for short strings. However, the algorithm&rsquo;s time complexity is \(O(m*n)\), if two strings&rsquo; lengths are \(m\) and \(n\) respectively. So it&rsquo;s not suitable for large corpus. Also, if two corpus consists of same paragraph but the order is not same."><meta property="og:type" content="article"><meta property="og:url" content="https://www.fromkk.com/posts/near-duplicate-with-simhash/"><meta property="article:published_time" content="2019-12-04T00:16:00+08:00"><meta property="article:modified_time" content="2020-05-30T22:22:51+08:00"><title>Near-duplicate with SimHash · KK's Blog (fromkk)</title><link rel=canonical href=https://www.fromkk.com/posts/near-duplicate-with-simhash/><link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/fork-awesome@1.1.7/css/fork-awesome.min.css integrity="sha256-gsmEoJAws/Kd3CjuOQzLie5Q3yshhvmo7YNtBG7aaEY=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin=anonymous><link rel=stylesheet href=https://www.fromkk.com/css/coder.min.9836c03fe5c87d102278a33e86d0591ef36c89b1e17e8e547ebf84c05cee010e.css integrity="sha256-mDbAP+XIfRAieKM+htBZHvNsibHhfo5Ufr+EwFzuAQ4=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://www.fromkk.com/icons/icon-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://www.fromkk.com/icons/icon-192x192.png><meta name=generator content="Hugo 0.68.3"></head><body class=colorscheme-light><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://www.fromkk.com/>KK's Blog (fromkk)</a>
<span id=dark-mode-toggle class=float-right><i class="fa fa-adjust fa-fw" aria-hidden=true></i></span><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/tags/>Tags</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/index.xml>RSS</a></li><li class="navigation-item separator"><span>|</span></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title>Near-duplicate with SimHash</h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i><time datetime=2019-12-04T00:16:00+08:00>12/04/2019</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>4-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i><a href=https://www.fromkk.com/tags/machine-learning/>Machine Learning</a>
<span class=separator>•</span>
<a href=https://www.fromkk.com/tags/simhash/>SimHash</a></div></div></header><div><p>Before talking about <strong>SimHash</strong>, let&rsquo;s review some other methods which can also identify duplication.</p><h2 id=longest-common-subsequence--lcs>Longest Common Subsequence(LCS)</h2><p>This is the algorithm used by <code>diff</code> command. It is also <strong>edit distance</strong> with insertion and deletion as the only two edit operations.</p><p>This works good for short strings. However, the algorithm&rsquo;s time complexity is \(O(m*n)\), if two strings&rsquo; lengths are \(m\) and \(n\) respectively. So it&rsquo;s not suitable for large corpus. Also, if two corpus consists of same paragraph but the order is not same. LCS treat them as different corpus, and that&rsquo;s not we expected.</p><h2 id=bag-of-words--bow>Bag of Words(BoW)</h2><p>Transform document into the words it contains, then using Jaccard Similarity to calculate the similarity.</p><p>For example, if document A contains <code>{a,b,c}</code> and B contains <code>{a,b,d}</code>, then \[Similarity = \frac{A \cap B}{A \cap B} = \frac{\{a,b\}}{\{a,b,c,d\}}=\frac{1}{2}\]</p><h2 id=shingling--n-gram>Shingling (n-gram)</h2><p>BoW drops the word context information. In order to take word context into consideration, we convert sentences into phrases. For instance, <code>roses are red and violets are blue</code> will convert to <code>roses are red</code>, <code>are red and</code>, <code>red and voilets</code> &mldr;</p><h2 id=hashing>Hashing</h2><p>Saving shingling result take k times disk space if using k words phrase. To solve this problem, save phrase&rsquo;s hashing value instead of string.</p><figure><img src=https://www.fromkk.com/images/simhash_hashing.png width=600></figure><h2 id=minhash>MinHash</h2><p>The larger the document is, the more the hashing needs to compare. Is there a way to map documents to constant value? <strong>MinHash</strong> tackles this problem.</p><p>It uses \(k\) hashing functions to calculate the phrase hashes. Then for each hashing function, using the minimal hashing result as signature. Finally, we get \(k\) hashing value as document&rsquo;s signature. The procedure is shown below.</p><figure><img src=https://www.fromkk.com/images/simhash_minhash1.png width=600></figure><figure><img src=https://www.fromkk.com/images/simhash_minhash2.png width=600></figure><p>Compare with Hashing, <strong>MinHash</strong> successfully reduce the time complexity and storage complexity to \(O(1)\), an improvement over \(O(m+n)\) and \(O(n)\), where n is the phrase number, m is the phrase number to compare.</p><h2 id=simhash>SimHash</h2><p>For a given document, how to find it&rsquo;s most similar document? If using <strong>MinHash</strong>, we need to travel the whole corpus. Is there any more effective method? <strong>SimHash</strong> comes to the rescue.</p><p>For a set of input hashes, <strong>SimHash</strong> will generate a fingerprint(f-bits vector) for the input And the produced hashes has a property: similar input hashes generate similar fingerprint. So the dissimilarity of two documents can be calculated by the <code>XOR</code> of two fingerprint. In google&rsquo;s <a href=https://www2007.org/papers/paper215.pdf>Detecting Near-Duplicates for Web Crawling</a> paper, they map 8B web-pages to 64 bits. If two bits differ less than <strong>3</strong> bits, then two web-pages are similar.</p><p>The calculation of <strong>SimHash</strong> is quiet simple. Given a set of features extracted from the document and their weights, we&rsquo;ll maintain f-bits vector \(V\), and initialize it to zero. Each feature will also hash to f-bit value \(V_i\). Then each dimension of \(V_i\) will multiply by it&rsquo;s weight \(W_i\) and add this new value to \(V\). If i-th bits if 1, then \(V\) is incremented by the weight of that feature. Otherwise \(V\) is decremented by the weight. When all features have been processed, \(V\) contains positive and negative dimension. Mapping positive values to <code>1</code> and negative numbers to <code>0</code> to get the final hash value.</p><p>\[V = zero\_or\_one(\sum{W_i*inc\_or\_dec(V_i)})\]</p><h3 id=how-to-generate-features-from-document>How to generate features from document</h3><p>One easy way to do this is to use a window to get sub-string from document. For each sub-string, using the hash value of string as features, and the count of this string as weight.</p><p>For example, if we has this sentence: <code>kk really rocks!</code>.</p><p>First, pre-processing this sentence to <code>kkreallyrocks</code>.</p><p>Then using a window of 4 to generate sub-string from the sentence. We&rsquo;ll get the sub-string and their count: <code>(kkre, 1), (krea, 1)</code>, <code>(real, 1)</code> etc.</p><p>Suppose we only get these first 3 sub-string and their hash values are <code>1001</code>, <code>0101</code> and <code>1101</code> respectively. Then the final \(V\) should be <code>1101</code></p><figure><img src=https://www.fromkk.com/images/simhash.png width=500></figure><h3 id=how-to-find-similar-document>How to find similar document</h3><p>Iterating over all document and compare with target simhash value is a time consuming operation. Is there any smart way to accomplish this task? In Google&rsquo;s paper, they published a very neat algorithm.</p><p>If the hash value is a 64-bit vector, and we want to find the document which is 2-bit differs with the target. Then we can divided the vector to 4 part: \(A\), \(B\), \(C\) and \(D\). Then we know that at least two part should be the identical.</p><p>Suppose part \(A\) and \(B\) is identical, if we have sorted the hash by \(ABCD\) order, we can easily find all hash that \(AB\) part is identical. Then we can compare the rest part \(B\) and \(C\) and find hash vectors that differs from target at most 2 bit. If you have 8B(\(2^{34}\)) document and documents are distributed uniformly at random, on average, you only need to compare \(2^{34-32}=4\) fingerprints.</p><figure><img src=https://www.fromkk.com/images/simhash_query1.png></figure><p>Besides \(AB\), \(AC\), \(AD\), \(BC\), \(BD\) and \(CD\) may also be identical. So you need to keep \(C_4^2=6\) sorted list, and compare 4 fingerprints in each list. You don&rsquo;t need to compare 8B documents anymore, that&rsquo;s a great improvement.</p><figure><img src=https://www.fromkk.com/images/simhash_query2.png></figure><p>Depending on the fingerprints&rsquo; bit and documents number, you need to find a optimal number to split the hash value.</p><h2 id=ref>Ref:</h2><ol><li><a href=https://moz.com/devblog/near-duplicate-detection>Near-Duplicate Detection</a></li><li><a href=https://www2007.org/papers/paper215.pdf>Detecting Near-Duplicates for Web Crawling</a></li><li><a href=https://github.com/seomoz/simhash-py>simhash-py</a></li></ol></div><footer><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"kkblog-1"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></footer></article><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js id=MathJax-script></script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}};</script></section></div><footer class=footer><section class=container>©
2020
KK
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=https://www.fromkk.com/js/dark-mode.min.0213e1773e6d1c5a644f847c67a6f8abac49a3776e2976f6008038af8c5b76a1.js></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-153788833-1','auto');ga('send','pageview');}</script></body></html>