<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=content-language content="en"><meta name=color-scheme content="light dark"><meta name=author content="KK"><meta name=description content="\(s_t\) and \(h_i\) are source hidden states and target hidden state, the shape is (n,1). \(c_t\) is the final context vector, and \(\alpha_{t,s}\) is alignment score.
\[\begin{aligned} c_t&=\sum_{i=1}^n \alpha_{t,s}h_i \\\
\alpha_{t,s}&= \frac{\exp(score(s_t,h_i))}{\sum_{i=1}^n \exp(score(s_t,h_i))} \end{aligned}\]
Global(Soft) VS Local(Hard) Global Attention takes all source hidden states into account, and local attention only use part of the source hidden states.
Content-based VS Location-based Content-based Attention uses both source hidden states and target hidden states, but location-based attention only use source hidden states."><meta name=keywords content="fromkk,blog,kk blog,developer,personal,python,golang,go,linux,machine learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="Different Types of Attention"><meta name=twitter:description content="\(s_t\) and \(h_i\) are source hidden states and target hidden state, the shape is (n,1). \(c_t\) is the final context vector, and \(\alpha_{t,s}\) is alignment score.
\[\begin{aligned} c_t&=\sum_{i=1}^n \alpha_{t,s}h_i \\\
\alpha_{t,s}&= \frac{\exp(score(s_t,h_i))}{\sum_{i=1}^n \exp(score(s_t,h_i))} \end{aligned}\]
Global(Soft) VS Local(Hard) Global Attention takes all source hidden states into account, and local attention only use part of the source hidden states.
Content-based VS Location-based Content-based Attention uses both source hidden states and target hidden states, but location-based attention only use source hidden states."><meta property="og:title" content="Different Types of Attention"><meta property="og:description" content="\(s_t\) and \(h_i\) are source hidden states and target hidden state, the shape is (n,1). \(c_t\) is the final context vector, and \(\alpha_{t,s}\) is alignment score.
\[\begin{aligned} c_t&=\sum_{i=1}^n \alpha_{t,s}h_i \\\
\alpha_{t,s}&= \frac{\exp(score(s_t,h_i))}{\sum_{i=1}^n \exp(score(s_t,h_i))} \end{aligned}\]
Global(Soft) VS Local(Hard) Global Attention takes all source hidden states into account, and local attention only use part of the source hidden states.
Content-based VS Location-based Content-based Attention uses both source hidden states and target hidden states, but location-based attention only use source hidden states."><meta property="og:type" content="article"><meta property="og:url" content="https://www.fromkk.com/posts/different-types-of-attention/"><meta property="article:published_time" content="2019-07-15T00:16:00+08:00"><meta property="article:modified_time" content="2020-04-02T21:08:18+08:00"><title>Different Types of Attention · KK's Blog (fromkk)</title><link rel=canonical href=https://www.fromkk.com/posts/different-types-of-attention/><link rel=preload href="https://www.fromkk.com/fonts/forkawesome-webfont.woff2?v=1.1.7" as=font type=font/woff2 integrity="sha256-hEIt6X6xzye8ubyk8/uxjz68cRZHsJxoKS9fQ8idUGQ=" crossorigin><link rel=stylesheet href=https://www.fromkk.com/css/coder.min.ec198d25949ddd79a670b1ead43ca88e0bc2c1343266d0df0a9eeb7f3f207777.css integrity="sha256-7BmNJZSd3XmmcLHq1DyojgvCwTQyZtDfCp7rfz8gd3c=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://www.fromkk.com/css/coder-dark.min.89c82b6022b96f77aeb521b240daec4f87ea029d84d1c78b8acd0735b91b3c92.css integrity="sha256-icgrYCK5b3eutSGyQNrsT4fqAp2E0ceLis0HNbkbPJI=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://www.fromkk.com/icons/icon-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://www.fromkk.com/icons/icon-192x192.png><meta name=generator content="Hugo 0.68.3"></head><body class=colorscheme-auto><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://www.fromkk.com/>KK's Blog (fromkk)</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/tags/>Tags</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/index.xml>RSS</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://www.fromkk.com/posts/different-types-of-attention/>Different Types of Attention</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i><time datetime=2019-07-15T00:16:00+08:00>07/15/2019</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>One-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i><a href=https://www.fromkk.com/tags/machine-learning/>Machine Learning</a></div></div></header><div><p>\(s_t\) and \(h_i\) are source hidden states and target hidden state, the shape is <code>(n,1)</code>. \(c_t\) is the final context vector, and \(\alpha_{t,s}\) is alignment score.</p><p>\[\begin{aligned}
c_t&=\sum_{i=1}^n \alpha_{t,s}h_i \\\<br>\alpha_{t,s}&= \frac{\exp(score(s_t,h_i))}{\sum_{i=1}^n \exp(score(s_t,h_i))}
\end{aligned}\]</p><h2 id=global--soft--vs-local--hard>Global(Soft) VS Local(Hard)</h2><p>Global Attention takes all source hidden states into account, and local attention only use part of the source hidden states.</p><h2 id=content-based-vs-location-based>Content-based VS Location-based</h2><p>Content-based Attention uses both source hidden states and target hidden states, but location-based attention only use source hidden states.</p><p>Here are several popular attention mechanisms:</p><h4 id=dot-product>Dot-Product</h4><p>\[score(s_t,h_i)=s_t^Th_i\]</p><h4 id=scaled-dot-product>Scaled Dot-Product</h4><p>\[score(s_t,h_i)=\frac{s_t^Th_i}{\sqrt{n}}\]
where n is the vectors dimension. Google&rsquo;s Transformer model has similar scaling factor when calculate self-attention: \(score=\frac{KQ^T}{\sqrt{n}}\)</p><h4 id=location-base>Location-Base</h4><p>\[socre(s_t,h_i)=softmax(W_as_t)\]</p><h4 id=general>General</h4><p>\[score(s_t,h_i)=s_t^TW_ah_i\]</p><p>\(Wa\)&lsquo;s shape is <code>(n,n)</code></p><h4 id=concat>Concat</h4><p>\[score(s_t,h_i)=v_a^Ttanh(W_a[s_t,h_i])\]</p><p>\(v_a\)&lsquo;s shape is <code>(x,1)</code>, and \(Wa\) &lsquo;s shape is <code>(x,x)</code>. This is similar to a neural network with one hidden layer.</p><p>When I doing a slot filling project, I compare these mechanisms. <strong>Concat</strong> attention produce the best result.</p><h2 id=ref>Ref:</h2><ol><li><a href=http://cnyah.com/2017/08/01/attention-variants/>Attention Variants</a></li><li><a href=https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html>Attention? Attention!</a></li><li><a href=https://towardsdatascience.com/attention-seq2seq-with-pytorch-learning-to-invert-a-sequence-34faf4133e53>Attention Seq2Seq with PyTorch: learning to invert a sequence</a></li></ol></div><footer><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"kkblog-1"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></footer></article><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}};</script></section></div><footer class=footer><section class=container>©
2021
KK
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=https://www.fromkk.com/js/dark-mode.min.0213e1773e6d1c5a644f847c67a6f8abac49a3776e2976f6008038af8c5b76a1.js integrity="sha256-AhPhdz5tHFpkT4R8Z6b4q6xJo3duKXb2AIA4r4xbdqE="></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-153788833-1','auto');ga('send','pageview');}</script></body></html>