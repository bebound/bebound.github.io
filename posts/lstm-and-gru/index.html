<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=content-language content="en"><meta name=color-scheme content="light dark"><meta name=author content="KK"><meta name=description content="LSTM    The avoid the problem of vanishing gradient and exploding gradient in vanilla RNN, LSTM was published, which can remember information for longer periods of time.
Here is the structure of LSTM:
 The calculate procedure are:
\[\begin{aligned} f_t&=\sigma(W_f\cdot[h_{t-1},x_t]+b_f)\\\ i_t&=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)\\\ o_t&=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)\\\ \tilde{C_t}&=tanh(W_C\cdot[h_{t-1},x_t]+b_C)\\\ C_t&=f_t\ast C_{t-1}+i_t\ast \tilde{C_t}\\\ h_t&=o_t \ast tanh(C_t) \end{aligned}\]
\(f_t\),\(i_t\),\(o_t\) are forget gate, input gate and output gate respectively. \(\tilde{C_t}\) is the new memory content. \(C_t\) is cell state."><meta name=keywords content="fromkk,blog,kk blog,developer,personal,python,golang,go,linux,machine learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="LSTM and GRU"><meta name=twitter:description content="LSTM    The avoid the problem of vanishing gradient and exploding gradient in vanilla RNN, LSTM was published, which can remember information for longer periods of time.
Here is the structure of LSTM:
 The calculate procedure are:
\[\begin{aligned} f_t&=\sigma(W_f\cdot[h_{t-1},x_t]+b_f)\\\ i_t&=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)\\\ o_t&=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)\\\ \tilde{C_t}&=tanh(W_C\cdot[h_{t-1},x_t]+b_C)\\\ C_t&=f_t\ast C_{t-1}+i_t\ast \tilde{C_t}\\\ h_t&=o_t \ast tanh(C_t) \end{aligned}\]
\(f_t\),\(i_t\),\(o_t\) are forget gate, input gate and output gate respectively. \(\tilde{C_t}\) is the new memory content. \(C_t\) is cell state."><meta property="og:title" content="LSTM and GRU"><meta property="og:description" content="LSTM    The avoid the problem of vanishing gradient and exploding gradient in vanilla RNN, LSTM was published, which can remember information for longer periods of time.
Here is the structure of LSTM:
 The calculate procedure are:
\[\begin{aligned} f_t&=\sigma(W_f\cdot[h_{t-1},x_t]+b_f)\\\ i_t&=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)\\\ o_t&=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)\\\ \tilde{C_t}&=tanh(W_C\cdot[h_{t-1},x_t]+b_C)\\\ C_t&=f_t\ast C_{t-1}+i_t\ast \tilde{C_t}\\\ h_t&=o_t \ast tanh(C_t) \end{aligned}\]
\(f_t\),\(i_t\),\(o_t\) are forget gate, input gate and output gate respectively. \(\tilde{C_t}\) is the new memory content. \(C_t\) is cell state."><meta property="og:type" content="article"><meta property="og:url" content="https://www.fromkk.com/posts/lstm-and-gru/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-04-22T14:39:00+08:00"><meta property="article:modified_time" content="2019-11-29T00:29:04+08:00"><title>LSTM and GRU · KK's Blog (fromkk)</title><link rel=canonical href=https://www.fromkk.com/posts/lstm-and-gru/><link rel=preload href="https://www.fromkk.com/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=https://www.fromkk.com/css/coder.min.d9fddbffe6f27e69985dc5fe0471cdb0e57fbf4775714bc3d847accb08f4a1f6.css integrity="sha256-2f3b/+byfmmYXcX+BHHNsOV/v0d1cUvD2Eesywj0ofY=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://www.fromkk.com/css/coder-dark.min.002ee2378e14c7a68f1f0a53d9694ed252090987c4e768023fac694a4fc5f793.css integrity="sha256-AC7iN44Ux6aPHwpT2WlO0lIJCYfE52gCP6xpSk/F95M=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://www.fromkk.com/icons/icon-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://www.fromkk.com/icons/icon-192x192.png><meta name=generator content="Hugo 0.94.2"></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://www.fromkk.com/>KK's Blog (fromkk)</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/tags/>Tags</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/index.xml>RSS</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://www.fromkk.com/posts/lstm-and-gru/>LSTM and GRU</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2018-04-22T14:39:00+08:00>04/22/2018</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
One-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=https://www.fromkk.com/tags/machine-learning/>Machine Learning</a></span>
<span class=separator>•</span>
<span class=tag><a href=https://www.fromkk.com/tags/lstm/>LSTM</a></span>
<span class=separator>•</span>
<span class=tag><a href=https://www.fromkk.com/tags/gru/>GRU</a></span></div></div></header><div><h2 id=lstm>LSTM
<a class=heading-link href=#lstm><i class="fa fa-link" aria-hidden=true></i></a></h2><p>The avoid the problem of vanishing gradient and exploding gradient in vanilla RNN, LSTM was published, which can remember information for longer periods of time.</p><p>Here is the structure of LSTM:</p><figure><img src=https://www.fromkk.com/images/LSTM_LSTM.png width=400></figure><p>The calculate procedure are:</p><p>\[\begin{aligned}
f_t&=\sigma(W_f\cdot[h_{t-1},x_t]+b_f)\\\
i_t&=\sigma(W_i\cdot[h_{t-1},x_t]+b_i)\\\
o_t&=\sigma(W_o\cdot[h_{t-1},x_t]+b_o)\\\
\tilde{C_t}&=tanh(W_C\cdot[h_{t-1},x_t]+b_C)\\\
C_t&=f_t\ast C_{t-1}+i_t\ast \tilde{C_t}\\\
h_t&=o_t \ast tanh(C_t)
\end{aligned}\]</p><p>\(f_t\),\(i_t\),\(o_t\) are forget gate, input gate and output gate respectively. \(\tilde{C_t}\) is the new memory content. \(C_t\) is cell state. \(h_t\) is the output.</p><p>Use \(f_t\) and \(i_t\) to update \(C_t\), use \(o_t\) to decide which part of hidden state should be outputted.</p><h2 id=gru>GRU
<a class=heading-link href=#gru><i class="fa fa-link" aria-hidden=true></i></a></h2><figure><img src=https://www.fromkk.com/images/LSTM_GRU.png width=400></figure><p>\[\begin{aligned}
z_t&=\sigma(W_z\cdot[h_{t-1},x_t])\\\
r_t&=\sigma(W_r\cdot[h_{t-1},x_t])\\\
\tilde{h_t}&=tanh(W\cdot[r_t \ast h_{t-1},x_t])\\\
h_t&=(1-z_t)\ast h_{t-1}+z_t \ast \tilde{h_t}
\end{aligned}\]</p><p>\(z_t\) is update gate, \(r_t\) is reset gate, \(\tilde{h_t}\) is candidate activation, \(h_t\) is activation.</p><p>Compare with LSTM, GRU merge cell state and hidden state to one hidden state, and use \(z_t\) to decide how to update the state rather than \(f_t\) and \(i_t\).</p><h2 id=ref>Ref:
<a class=heading-link href=#ref><i class="fa fa-link" aria-hidden=true></i></a></h2><ol><li><a href=http://colah.github.io/posts/2015-08-Understanding-LSTMs/>Understanding LSTM Networks</a></li></ol></div><footer><script src=https://utteranc.es/client.js repo=bebound/bebound.github.io issue-term=pathname label=comment theme=preferred-color-scheme crossorigin=anonymous async></script></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2022
KK
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=https://www.fromkk.com/js/coder.min.8fb86376a16e684af472a329aef502dbebcfab65ce264e9750d144912947c602.js integrity="sha256-j7hjdqFuaEr0cqMprvUC2+vPq2XOJk6XUNFEkSlHxgI="></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-153788833-1","auto"),ga("send","pageview"))</script></body></html>