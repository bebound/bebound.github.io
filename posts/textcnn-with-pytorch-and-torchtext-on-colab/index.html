<!doctype html><html lang=en><head><title>TextCNN with PyTorch and Torchtext on Colab · KK's Blog (fromkk)</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="KK"><meta name=description content="PyTorch is a really powerful framework to build the machine learning models. Although some features is missing when compared with TensorFlow (For example, the early stop function, History to draw plot), its code style is more intuitive.
Torchtext is a NLP package which is also made by pytorch team. It provide a way to read text, processing and iterate the texts.
Google Colab is a Jupyter notebook environment host by Google, you can use free GPU and TPU to run your modal."><meta name=keywords content="fromkk,blog,kk blog,developer,personal,python,golang,go,linux,machine learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="TextCNN with PyTorch and Torchtext on Colab"><meta name=twitter:description content="PyTorch is a really powerful framework to build the machine learning models. Although some features is missing when compared with TensorFlow (For example, the early stop function, History to draw plot), its code style is more intuitive.
Torchtext is a NLP package which is also made by pytorch team. It provide a way to read text, processing and iterate the texts.
Google Colab is a Jupyter notebook environment host by Google, you can use free GPU and TPU to run your modal."><meta property="og:title" content="TextCNN with PyTorch and Torchtext on Colab"><meta property="og:description" content="PyTorch is a really powerful framework to build the machine learning models. Although some features is missing when compared with TensorFlow (For example, the early stop function, History to draw plot), its code style is more intuitive.
Torchtext is a NLP package which is also made by pytorch team. It provide a way to read text, processing and iterate the texts.
Google Colab is a Jupyter notebook environment host by Google, you can use free GPU and TPU to run your modal."><meta property="og:type" content="article"><meta property="og:url" content="https://www.fromkk.com/posts/textcnn-with-pytorch-and-torchtext-on-colab/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-12-03T15:47:00+08:00"><meta property="article:modified_time" content="2020-03-26T21:22:08+08:00"><link rel=canonical href=https://www.fromkk.com/posts/textcnn-with-pytorch-and-torchtext-on-colab/><link rel=preload href="https://www.fromkk.com/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=https://www.fromkk.com/css/coder.min.ea4c355c5f9913809f506132a80bf3fab84f2679dee370f334f7385a36d24c38.css integrity="sha256-6kw1XF+ZE4CfUGEyqAvz+rhPJnne43DzNPc4WjbSTDg=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://www.fromkk.com/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=https://www.fromkk.com/images/favicon.svg sizes=any><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://www.fromkk.com/icons/icon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://www.fromkk.com/icons/icon-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://www.fromkk.com/icons/icon-192x192.png><link rel=manifest href=https://www.fromkk.com/site.webmanifest><link rel=mask-icon href=https://www.fromkk.com/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://www.fromkk.com/>KK's Blog (fromkk)</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/tags/>Tags</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://www.fromkk.com/posts/index.xml>RSS</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://www.fromkk.com/posts/textcnn-with-pytorch-and-torchtext-on-colab/>TextCNN with PyTorch and Torchtext on Colab</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2018-12-03T15:47:00+08:00>12/03/2018</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
4-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=https://www.fromkk.com/tags/machine-learning/>Machine Learning</a></span>
<span class=separator>•</span>
<span class=tag><a href=https://www.fromkk.com/tags/textcnn/>TextCNN</a></span></div></div></header><div class=post-content><p><a href=https://pytorch.org class=external-link target=_blank rel=noopener>PyTorch</a> is a really powerful framework to build the machine learning models. Although some features is missing when compared with TensorFlow (For example, the early stop function, History to draw plot), its code style is more intuitive.</p><p><a href=https://github.com/pytorch/text class=external-link target=_blank rel=noopener>Torchtext</a> is a NLP package which is also made by <code>pytorch</code> team. It provide a way to read text, processing and iterate the texts.</p><p><a href=https://colab.research.google.com class=external-link target=_blank rel=noopener>Google Colab</a> is a Jupyter notebook environment host by Google, you can use free GPU and TPU to run your modal.</p><p>Here is a simple tuturial to build a TextCNN modal and run it on Colab.</p><p>The <a href=https://arxiv.org/abs/1408.5882 class=external-link target=_blank rel=noopener>TextCNN paper</a> was published by Kim in 2014. The model&rsquo;s idea is pretty simple, but the performance is impressive. If you trying to solve the text classificaton problem, this model is a good choice to start with.</p><p>The main architecture is shown below:</p><figure><img src=https://www.fromkk.com/images/textcnn.png width=400></figure><p>It uses different kernels to extract text features, then use the softmax regression to classify text base on the features.</p><p>Now we can build this model step by step.</p><p>First build the model. The model I use is CNN-multichannel, which contains two sets of word embedding. Both of them is the copy of word embedding generate from corpus, but only one set will update embedding during training.</p><p>The code is below:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>textCNNMulti</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self,args):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        dim <span style=color:#f92672>=</span> args[<span style=color:#e6db74>&#39;dim&#39;</span>]
</span></span><span style=display:flex><span>        n_class <span style=color:#f92672>=</span> args[<span style=color:#e6db74>&#39;n_class&#39;</span>]
</span></span><span style=display:flex><span>        embedding_matrix<span style=color:#f92672>=</span>args[<span style=color:#e6db74>&#39;embedding_matrix&#39;</span>]
</span></span><span style=display:flex><span>        kernels<span style=color:#f92672>=</span>[<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>5</span>]
</span></span><span style=display:flex><span>        kernel_number<span style=color:#f92672>=</span>[<span style=color:#ae81ff>150</span>,<span style=color:#ae81ff>150</span>,<span style=color:#ae81ff>150</span>]
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>static_embed <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding<span style=color:#f92672>.</span>from_pretrained(embedding_matrix)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>non_static_embed <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Embedding<span style=color:#f92672>.</span>from_pretrained(embedding_matrix, freeze<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>convs <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ModuleList([nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>2</span>, number, (size, dim),padding<span style=color:#f92672>=</span>(size<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>0</span>)) <span style=color:#66d9ef>for</span> (size,number) <span style=color:#f92672>in</span> zip(kernels,kernel_number)])
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>dropout<span style=color:#f92672>=</span>nn<span style=color:#f92672>.</span>Dropout()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>out <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(sum(kernel_number), n_class)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        non_static_input <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>non_static_embed(x)
</span></span><span style=display:flex><span>        static_input <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>static_embed(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>stack([non_static_input, static_input], dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> [F<span style=color:#f92672>.</span>relu(conv(x))<span style=color:#f92672>.</span>squeeze(<span style=color:#ae81ff>3</span>) <span style=color:#66d9ef>for</span> conv <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>convs]
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> [F<span style=color:#f92672>.</span>max_pool1d(i, i<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>2</span>))<span style=color:#f92672>.</span>squeeze(<span style=color:#ae81ff>2</span>) <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> x]
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat(x, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>dropout(x)
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>out(x)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> x
</span></span></code></pre></div><p>Second, convert text into word index, so each sentence become a vector for training.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span>TEXT <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>Field(lower<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,batch_first<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>LABEL <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>LabelField()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train, val, test <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>SST<span style=color:#f92672>.</span>splits(TEXT, LABEL, <span style=color:#e6db74>&#39;data/&#39;</span>,fine_grained<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>TEXT<span style=color:#f92672>.</span>build_vocab(train, vectors<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;glove.840B.300d&#34;</span>)
</span></span><span style=display:flex><span>LABEL<span style=color:#f92672>.</span>build_vocab(train,val,test)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_iter, val_iter, test_iter <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>BucketIterator<span style=color:#f92672>.</span>splits(
</span></span><span style=display:flex><span>    (train, val, test), batch_sizes<span style=color:#f92672>=</span>(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>),shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><p><code>Field</code> defines how to process text, here is the most common parameters:</p><blockquote><p>sequential – Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True.</p><p>use_vocab – Whether to use a Vocab object. If False, the data in this field should already be numerical. Default: True.</p><p>preprocessing – The Pipeline that will be applied to examples using this field after tokenizing but before numericalizing. Many Datasets replace this attribute with a custom preprocessor. Default: None.</p><p>batch_first – Whether to produce tensors with the batch dimension first. Default: False.</p></blockquote><p><code>datasets.SST.splits</code> will load the <code>SST</code> datasets, and split into train, validation, and test Dataset objects.</p><p><code>build_vocab</code> will create the Vocab object for Field, which contains the information to convert word into word index and vice versa. Also, the word embedding will save as <code>Field.Vocab.vectors</code>. <code>vectors</code> contains all of the word embedding. Torchtext can download some pretrained vectors automatically, such as <code>glove.840B.300d</code>, <code>fasttext.en.300d</code>. You can also load your vectors in this way, <code>xxx.vec</code> should be the standard word2vec format.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> torchtext.vocab <span style=color:#f92672>import</span> Vectors
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>vectors <span style=color:#f92672>=</span> Vectors(name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;xxx.vec&#39;</span>, cache<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./&#39;</span>)
</span></span><span style=display:flex><span>TEXT<span style=color:#f92672>.</span>build_vocab(train, val, test, vectors<span style=color:#f92672>=</span>vectors)
</span></span></code></pre></div><p><code>data.BucketIterator.splits</code> will returns iterators that loads batches of data from datasets, and the text in same batch has similar lengths.</p><p>Now, we can start to train the model. First we wrap some parameters into <code>args</code>, it contains settings like output class, learning rate, log interval and so on.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>args<span style=color:#f92672>=</span>{}
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;vocb_size&#39;</span>]<span style=color:#f92672>=</span>len(TEXT<span style=color:#f92672>.</span>vocab)
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;dim&#39;</span>]<span style=color:#f92672>=</span><span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;n_class&#39;</span>]<span style=color:#f92672>=</span>len(LABEL<span style=color:#f92672>.</span>vocab)
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;embedding_matrix&#39;</span>]<span style=color:#f92672>=</span>TEXT<span style=color:#f92672>.</span>vocab<span style=color:#f92672>.</span>vectors
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;lr&#39;</span>]<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;momentum&#39;</span>]<span style=color:#f92672>=</span><span style=color:#ae81ff>0.8</span>
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;epochs&#39;</span>]<span style=color:#f92672>=</span><span style=color:#ae81ff>180</span>
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;log_interval&#39;</span>]<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;test_interval&#39;</span>]<span style=color:#f92672>=</span><span style=color:#ae81ff>500</span>
</span></span><span style=display:flex><span>args[<span style=color:#e6db74>&#39;save_dir&#39;</span>]<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./&#39;</span>
</span></span></code></pre></div><p>Finally, we can train the model.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model<span style=color:#f92672>=</span>textCNNMulti(args)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>cuda()
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>optim<span style=color:#f92672>.</span>SGD(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span>args[<span style=color:#e6db74>&#39;lr&#39;</span>],momentum<span style=color:#f92672>=</span>args[<span style=color:#e6db74>&#39;momentum&#39;</span>])
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span>steps<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>, args[<span style=color:#e6db74>&#39;epochs&#39;</span>]<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i,data <span style=color:#f92672>in</span> enumerate(train_iter):
</span></span><span style=display:flex><span>        steps<span style=color:#f92672>+=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        x, target <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>text, data<span style=color:#f92672>.</span>label
</span></span><span style=display:flex><span>        x<span style=color:#f92672>=</span>x<span style=color:#f92672>.</span>cuda()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        target<span style=color:#f92672>.</span>sub_(<span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        target<span style=color:#f92672>=</span>target<span style=color:#f92672>.</span>cuda()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> model(x)
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(output, target)
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span></code></pre></div><p>You can found <code>textcnn.ipynb</code> on <a href=https://github.com/bebound/textcnn class=external-link target=_blank rel=noopener>GitHub</a> or <a href="https://colab.research.google.com/drive/1iZE5O0aBEOEhkWNpARqK5u151qrlwJq-#scrollTo=qR-sHoABrMg3&amp;uniqifier=2" class=external-link target=_blank rel=noopener>Colab</a>.</p><h2 id=ref>Ref:
<a class=heading-link href=#ref><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ol><li><a href=https://arxiv.org/abs/1408.5882 class=external-link target=_blank rel=noopener>Convolutional Neural Networks for Sentence Classiﬁcation</a></li><li><a href=http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/ class=external-link target=_blank rel=noopener>Understanding Convolutional Neural Networks for NLP</a></li><li><a href=https://torchtext.readthedocs.io/en/latest/data.html class=external-link target=_blank rel=noopener>Torchtext Docs</a></li><li><a href=https://github.com/castorini/Castor class=external-link target=_blank rel=noopener>Castor</a></li></ol></div><footer><div class=comments><script>let getTheme=window.localStorage&&window.localStorage.getItem("colorscheme"),themeInParams="preferred-color-scheme";getTheme==null&&(themeInParams!==""&&themeInParams!=="auto"?getTheme=themeInParams:getTheme=window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");let theme=getTheme==="dark"?"github-dark":"github-light",s=document.createElement("script");s.src="https://utteranc.es/client.js",s.setAttribute("repo","bebound/bebound.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("theme",theme),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s)</script></div></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2023
KK
·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=https://www.fromkk.com/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-153788833-1","auto"),ga("send","pageview"))</script></body></html>