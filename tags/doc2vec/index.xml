<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>doc2vec on KK's Blog</title><link>https://www.fromkk.com/tags/doc2vec/</link><description>Recent content in doc2vec on KK's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 10 Sep 2017 15:29:00 +0800</lastBuildDate><atom:link href="https://www.fromkk.com/tags/doc2vec/index.xml" rel="self" type="application/rss+xml"/><item><title>Semi-supervised text classification using doc2vec and label spreading</title><link>https://www.fromkk.com/posts/semi-supervised-text-classification-using-doc2vec-and-label-spreading/</link><pubDate>Sun, 10 Sep 2017 15:29:00 +0800</pubDate><guid>https://www.fromkk.com/posts/semi-supervised-text-classification-using-doc2vec-and-label-spreading/</guid><description>Here is a simple way to classify text without much human effort and get a impressive performance.
It can be divided into two steps:
Get train data by using keyword classification Generate a more accurate classification model by using doc2vec and label spreading Keyword-based Classification #Keyword based classification is a simple but effective method.</description></item><item><title>Parameters in doc2vec</title><link>https://www.fromkk.com/posts/parameters-in-dov2vec/</link><pubDate>Thu, 03 Aug 2017 15:20:00 +0800</pubDate><guid>https://www.fromkk.com/posts/parameters-in-dov2vec/</guid><description>Here are some parameter in gensim&amp;rsquo;s doc2vec class.
window #window is the maximum distance between the predicted word and context words used for prediction within a document. It will look behind and ahead.
In skip-gram model, if the window size is 2, the training samples will be this:(the blue word is the input word)</description></item></channel></rss>