<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Label Propagation on KK's Blog (fromkk)</title><link>https://www.fromkk.com/tags/label-propagation/</link><description>Recent content in Label Propagation on KK's Blog (fromkk)</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License，please give source if you wish to quote or reproduce.</copyright><lastBuildDate>Sun, 16 Jul 2017 21:45:00 +0800</lastBuildDate><atom:link href="https://www.fromkk.com/tags/label-propagation/index.xml" rel="self" type="application/rss+xml"/><item><title>Brief Introduction of Label Propagation Algorithm</title><link>https://www.fromkk.com/posts/brief-introduction-of-label-propagation-algorithm/</link><pubDate>Sun, 16 Jul 2017 21:45:00 +0800</pubDate><guid>https://www.fromkk.com/posts/brief-introduction-of-label-propagation-algorithm/</guid><description>As I said before, I&amp;rsquo;m working on a text classification project. I use doc2vec to convert text into vectors, then I use LPA to classify the vectors.
LPA is a simple, effective semi-supervised algorithm. It can use the density of unlabeled data to find a hyperplane to split the data.
Here are the main stop of the algorithm:
Let $ (x_1,y1)&amp;hellip;(x_l,y_l)$ be labeled data, $Y_L = \{y_1&amp;hellip;y_l\} $ are the class labels.</description></item></channel></rss>